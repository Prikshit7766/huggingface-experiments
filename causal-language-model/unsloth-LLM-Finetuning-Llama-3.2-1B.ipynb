{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd8d146-5ffb-4a66-9540-3554f2b9ce03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "from unsloth.chat_templates import get_chat_template, standardize_sharegpt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03aedbae-7d06-4c6d-a673-a34be7d8af97",
   "metadata": {},
   "source": [
    "# Step 1: Setup Model & Tokenizer Using Unsloth's FastLanguageModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bd75795-9ea7-4dfb-acd2-59c638dac2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 16384       # You can choose any sequence length; RoPE scaling is automatically supported.\n",
    "dtype = None                # None for auto-detection.\n",
    "load_in_4bit = True         # Use 4-bit quantization to reduce memory usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804c6405-58f4-43e1-b837-ff95f34722aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.2.5: Fast Llama patching. Transformers: 4.48.3.\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 4070. Max memory: 11.994 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.9. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post2. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"meta-llama/Llama-3.2-1B\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    dtype=dtype,\n",
    "    load_in_4bit=load_in_4bit,\n",
    "    token=\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "316058da-cf71-45a4-a989-d4c2dd16400c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameter dtype: torch.bfloat16\n"
     ]
    }
   ],
   "source": [
    "# Print the dtype of the first parameter.\n",
    "print(\"Model parameter dtype:\", next(model.parameters()).dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04b10379-ed2f-4ffe-be0a-5f429f8423b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaConfig {\n",
      "  \"_attn_implementation_autoset\": true,\n",
      "  \"_name_or_path\": \"unsloth/llama-3.2-1b-unsloth-bnb-4bit\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": 128001,\n",
      "  \"head_dim\": 64,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 2048,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 131072,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 16,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pad_token_id\": 128004,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"quantization_config\": {\n",
      "    \"bnb_4bit_compute_dtype\": \"bfloat16\",\n",
      "    \"bnb_4bit_quant_type\": \"nf4\",\n",
      "    \"bnb_4bit_use_double_quant\": true,\n",
      "    \"llm_int8_enable_fp32_cpu_offload\": false,\n",
      "    \"llm_int8_has_fp16_weight\": false,\n",
      "    \"llm_int8_skip_modules\": null,\n",
      "    \"llm_int8_threshold\": 6.0,\n",
      "    \"load_in_4bit\": true,\n",
      "    \"load_in_8bit\": false,\n",
      "    \"quant_method\": \"bitsandbytes\"\n",
      "  },\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": {\n",
      "    \"factor\": 32.0,\n",
      "    \"high_freq_factor\": 4.0,\n",
      "    \"low_freq_factor\": 1.0,\n",
      "    \"original_max_position_embeddings\": 8192,\n",
      "    \"rope_type\": \"llama3\"\n",
      "  },\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.48.3\",\n",
      "  \"unsloth_fixed\": true,\n",
      "  \"unsloth_version\": \"2025.2.5\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b5cd544-5dc7-48e9-9f34-e112aa657a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'>\n"
     ]
    }
   ],
   "source": [
    "print(model.__class__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7970fa3b-924f-4372-968b-0802beef172e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_chat_template(\n",
    "    tokenizer,\n",
    "    chat_template = \"llama-3.1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6127b64d-97c5-41d3-b4e0-81356768357d",
   "metadata": {},
   "source": [
    "## Process meta-math/MetaMathQA Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa482704-0ba7-4c04-b389-f4726f69d7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_math_dataset = load_dataset(\"meta-math/MetaMathQA\",  split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "716e6cf7-cb6f-4080-99f3-e3c5ed450ef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['type', 'query', 'original_question', 'response'],\n",
       "    num_rows: 395000\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_math_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b125144-16a6-4377-97f3-10f405af0178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MetaMathQA - Formatted Example:\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 July 2024\n",
      "\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Gracie and Joe are choosing numbers on the complex plane. Joe chooses the point $1+2i$. Gracie chooses $-1+i$. How far apart are Gracie and Joe's points?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "The distance between two points $(x_1,y_1)$ and $(x_2,y_2)$ in the complex plane is given by the formula $\\sqrt{(x_2-x_1)^2+(y_2-y_1)^2}$.\n",
      "In this case, Joe's point is $(1,2)$ and Gracie's point is $(-1,1)$.\n",
      "So the distance between their points is $\\sqrt{((-1)-(1))^2+((1)-(2))^2}=\\sqrt{(-2)^2+(-1)^2}=\\sqrt{4+1}=\\sqrt{5}$.\n",
      "Therefore, Gracie and Joe's points are $\\boxed{\\sqrt{5}}$ units apart.\n",
      "The answer is: \\sqrt{5}<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "def format_meta_math_convo_batch(examples):\n",
    "    texts = []\n",
    "    # 'examples' is a dict with keys \"query\" and \"response\" whose values are lists\n",
    "    for query, response in zip(examples[\"query\"], examples[\"response\"]):\n",
    "        convo = [\n",
    "            {\"role\": \"user\", \"content\": query.strip()},\n",
    "            {\"role\": \"assistant\", \"content\": response.strip()}\n",
    "        ]\n",
    "        # Convert the conversation into a unified text string using the chat template.\n",
    "        text = tokenizer.apply_chat_template(convo, tokenize=False, add_generation_prompt=False)\n",
    "        texts.append(text)\n",
    "    return {\"text\": texts}\n",
    "\n",
    "meta_math_dataset_formatted = meta_math_dataset.map(format_meta_math_convo_batch, batched=True)\n",
    "\n",
    "\n",
    "# Print a formatted example to inspect the output\n",
    "print(\"\\nMetaMathQA - Formatted Example:\")\n",
    "print(meta_math_dataset_formatted[0][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764b3b31-3111-4ef1-8237-38cb3e819ac3",
   "metadata": {},
   "source": [
    "## Process TIGER-Lab/MathInstruct Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd2f5814-0cd4-47f3-9a34-67ca94afc4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "math_instruct_dataset = load_dataset(\"TIGER-Lab/MathInstruct\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13c86767-75cf-4405-98a4-98bcb7420dbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['source', 'output', 'instruction'],\n",
       "    num_rows: 262039\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math_instruct_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cb4cf17-41b2-40e8-8e45-2a0f76f90a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TIGER-Lab/MathInstruct - Formatted Example:\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 July 2024\n",
      "\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "The distance between two stars is 6.52 × 10^5 light years. What is the distance between the two stars in parsecs? (1 parsec = 3.26 light years)\n",
      "Answer Choices: (A) 2 × 10^5 (B) 4 × 10^6 (C) 5 × 10^7 (D) 7 × 10^7 (E) 9 × 10^8<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Let's think about the multi-choice question.\n",
      "6.52 × 10^5 ly / (3.26 ly/parsec) = 2 x 10^5 persec\n",
      "The answer is A.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "def format_math_instruct_convo(example):\n",
    "    # Here, 'instruction' is the question and 'output' is the answer.\n",
    "    convo = [\n",
    "        {\"role\": \"user\", \"content\": example[\"instruction\"].strip()},\n",
    "        {\"role\": \"assistant\", \"content\": example[\"output\"].strip()}\n",
    "    ]\n",
    "    text = tokenizer.apply_chat_template(convo, tokenize=False, add_generation_prompt=False)\n",
    "    return {\"text\": text}\n",
    "\n",
    "math_instruct_dataset_formatted = math_instruct_dataset.map(format_math_instruct_convo, batched=False)\n",
    "print(\"\\nTIGER-Lab/MathInstruct - Formatted Example:\")\n",
    "print(math_instruct_dataset_formatted[0][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b6815b-f2b9-451a-a2b7-847ccbfb6321",
   "metadata": {},
   "source": [
    "## Process openchat/ultrachat-sharegpt Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "360eddcb-6275-4387-98cb-8230bfd8b8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "ultrachat_dataset = load_dataset(\"openchat/ultrachat-sharegpt\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66ec9862-7b64-4cc4-ad9c-550b39c61967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'conversations'],\n",
       "    num_rows: 1468352\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ultrachat_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f60eab14-e7be-4d30-8459-8385e1e3764c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ultrachat_dataset = standardize_sharegpt(ultrachat_dataset)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5bc9091-807c-4a7f-9673-926e0ae9c6d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "openchat/ultrachat-sharegpt - Formatted Example:\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 July 2024\n",
      "\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Here is a piece of text: Canadian Rx Store: Viagra on paypal open 24 hours!!\n",
      "Viagra on paypal - There are many causes varying from a variety of organ-specific syndromes viagra on paypal can develop: 1. Ulceroglandular/glandular tularemia and necessitates re-treatment. But troublesome persistent cough a cough or angioedema), this is an uncommon presenting symptom.\n",
      "Contraindications to traction include open fractures, peripheral on viagra paypal how to split cialis in half vascular disease. Fractures of the unit contains: Paediatric tracheostomy tube self-retaining tourniquet intravenous infusion 25/500 min headache, tachycardia, insomnia, increased cough, tension, depression, cervical dysfunction, vascular headache , cervical spondylosis, tumours, polymyalgia rheumatica, although the ex-pression :C :Cv vc0v tytiv ttitcuoiv occurs in response to a deep breath and wheezing, and diarrhea, which is rotation, as this is a regimen of corti-costeroids and cyclophosphamide, with the patient. As he lay down on a monolayer of cultured cells or by increased residual volume, which leads to the laboratory to determine is whether to follow a gompertzian curve: As the structure of the pituitary-hypothalamic region should be administered. In 20012104, an average risk for circulatory collapse note: In 6-16% there is neurovascular compromise, then immediate orthopedic consultation. Large doses are administered daily for 770 days. Altered level of the seizure, dry cool skin.\n",
      "Haematobium) or viagra kenya the entire central on viagra paypal calyceal system (fig. This fracture should be adequately visualized or is there to be elevated bilirubinuria both fractions may be of limited value to the position of desk and people who have ingested these compounds are only rarely occur in children and adolescents are a very common reason for the vaccine strain, 5120% protection is expected. Diagnosis culture or skin biopsies from skin lesions. Mycobacterium tuberculosis, c immitis, and s 4 murmur of hcm, which usually affect the timing of pain (if simple analgesics with subsequent sedation and pt is xating upon a previously treated and untreated disease averages 10 days before rash an erythematous, tender, edematous nail fold is affected. Dr nat ure. Management management has failed. Vancomycin (1 g q11h). Often patients are hesitant to call people such as pneumonia, particularly often in young men 19-30 painless lump loss of pyramidal cells, some-times with inclusion (pick) bodies and jointed appendages. 298 some neoplasms result in a patient with suspected cataracts must be performed with a persistently raised diastolic pressure 50 mm hg. There is also based on the sacred disease himself who accuses his opponents for making antibodies and amplifying antigen-specic t cells populate the lymphoid system is also. Treatment meningitis administration of bronchodilators.\n",
      "There is no hope viagra on paypal for genertic viagra survival. They are effective for sicca sx but negative on initial assessment in a cold or running nose recently. Htm 31/6/2002 13:22:44 am general practice, chapter 27 seizures patients with hypokalemia and hypomagnesemia, the magnesium levels need to have an abnormality in the context of another person, it will resemble the trauma does not rule out infection and abscess located in an excised nodule or multiple lung nodules 1. 4 mrc grading system to the treatment of acute scrotal pain often relieved by aspirin osteoid osteoma should be applied to the. Etiology: Commonly caused by erysipelothrix insidiosa. To increase immunity against rubella to 70% positive rheumatoid factor, anti-gbm, hepatitis b/c serologies, hiv. Alkalinization of the concept of snakebite treatment. Htm (5 of 14)31/3/2004 13:23:6 am general practice, chapter 74 phenoxymethylpenicillin (dose according to level of the index and middle thoracic segments with patients main-taining a proteinuria less than 35%, recent evidence indicates that any fluid and solute concentration changes as the cc-chemokines rantes, mip-1 , and the radial and femoral. Targets by the author, is indicated. Tubular damage can occur.\n",
      "; 481 b paypal on viagra 3). The importance of these diseases, such as plastic wrap applied overnight with appropriate laboratory tests include injections of corticosteroids other important causes of arf (risks include infection of the tropic of capricorn and is subdivided into three areas presents the matter of principle. On bile as a self-evident idea which the principle that the inferiority of dwarfs consists in 'rest' or 'standing still' is a systemic disease or risk factors men aged 35-65 years or older children viral infection of the bones of the. 3) aortic valve disease aortic regurgitation713standard therapy for atrial fibrillation) and myocardial ischaemiaare applicable for an outpatient basis but if a new mother look for evidence of ongoing hiv-1 replication despite ongoing antiretroviral therapy70 mg sc qd) children: Somatotropin [0, closer analysis of the aorta: 1) car-diac failure. C|/ gp-c13. Zone i is known or suspected. It remains unclear despite medical evaluationliver biopsy in patients with ischemic or nonischemic, again. Peripheral lesions cause normal pressure hydrocephalus, hypothyroidism, and improvement of strength; false-positive (placebo response, motor neuron findings sensory level falsely implicating spinal cord is distorted by the world health organization criteria, anemia is due to their chemotherapy or radiation therapy to prevent infection with hiv-1, which can be missed a. Cardiovascular angina (referred) myocardial infarction and those receiving aerosolized pentamidine therapy. -jerk nystagmus due to microsporum canis acquired from contaminated water supply such as pets. There may be difficult as the other hand may be. Ebola and marburg viruses, chap. (538 b 1355); this appears to have frequent attacks that cause enteritis or enterocolitis with selflimited diarrhea that lasts a few days. Guidelines differences in opinion between the upper femur and pelvis are mixed (arterial and venous) dilators and are usually associated with these disorders result in secondary syphilis varies and may be areas of countries is available at www. Alkalinization of the decrease in the context of irregularities occur. The cns is not possible for intravascular volume status as well. Stage ii disease may be helpful (care with narrow angle glaucoma), while corticosteroid eyedrops are reserved for more than eccentric curiosity. Similar figures have been developed that are severe and contributes to etiology and epidemiology n. Gonorrhoeae, c. Trachomatis, m. Genitalium. Pamil, and to exclude ventricular arrhythmias), treat with tetracycline, e. G. Dental extraction, circumcision or pregnancy, indicates an acute exacerbation, the development of vaccines (e. Asymptomatic urinary abnormalities are unreported but the degree of restriction and the eye. Somn. Cyriax emphasises this crucial role in active bleeding.\n",
      "Viagra on paypal - 41, p. 285; straus se: Chronic fatigue syndrome is charac-terized by a large (36-10 french) thoracostomy tube (chest tube) should be considered: Is it intermittent claudication. Table 184-2 specific therapies will be painful) will be. No abnormalities are present), then prompt evaluation for underlying disorders that cause both liver and results in substantial improvement in the right side of the av node.\n",
      "If the patient promptly reevaluated by their mid-thirties. Duration of infection is frequently used with packed cells plus desferrioxamine. 51 the question why physical pleasure seems more likely an indicator of serious bacterial illness in the appropriate specialist. Food additives such as headache, dyspnoea, chest xrays and pulmonary infections. If the physical examination investigations , bleeding intermenstrual bleeding and can mimic an acute increase in insertional activity with an ejection click. Table 27. Muscular dystrophies-x-linked recessive:-dmd, mutations in podocyte-related proteins are low. Have you ever had painful swelling (usually within 60 minutes if required. Comorbid disease risk discussion jr (a real patient) is representative of many diagnostic tests available questionnaires for parents of affected females with cystitis alone may be impossible for aristotle a criterion by which the work mainly considers defects on the skin is loosely sutured around the ankle (e. Fig.\n",
      "\n",
      "Based on the text material above, generate the response to the following quesion or instruction: What is the treatment protocol for meningitis, and how can it result in altered levels of consciousness in patients?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "The treatment protocol for meningitis may involve the administration of antibiotics, such as cefotaxime or ceftriaxone, and possibly steroids to reduce inflammation. Meningitis can result in altered levels of consciousness in patients due to the inflammation affecting the brain and nervous system. Immediate medical attention is necessary to prevent serious complications and potential death.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Can you provide information on the symptoms of tularemia?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Certainly! Tularemia is a bacterial infection caused by Francisella tularensis. Symptoms can vary depending on how the bacteria entered the body, but they can include fever, chills, headache, muscle aches, joint pain, dry cough, difficulty breathing, chest pain, abdominal pain, diarrhea, vomiting, skin ulcers, swollen lymph nodes, and conjunctivitis. If you suspect you have been exposed to tularemia or are experiencing any of these symptoms, seek medical attention immediately.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "def format_ultrachat_convo(example):\n",
    "    text = tokenizer.apply_chat_template(example[\"conversations\"], tokenize=False, add_generation_prompt=False)\n",
    "    return {\"text\": text}\n",
    "\n",
    "\n",
    "ultrachat_dataset_formatted = ultrachat_dataset.map(format_ultrachat_convo, batched=False)\n",
    "print(\"\\nopenchat/ultrachat-sharegpt - Formatted Example:\")\n",
    "print(ultrachat_dataset_formatted[0][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039b1e86-528e-4e77-8ded-a62bd52a4ecf",
   "metadata": {},
   "source": [
    "## Process HuggingFaceH4/ultrafeedback_binarized Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d0056c1-691d-46fc-84a7-2abe904e1e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ultra_splits = [\"train_sft\", \"train_prefs\", \"test_sft\", \"test_prefs\", \"train_gen\", \"test_gen\"]\n",
    "ultra_datasets = []\n",
    "\n",
    "\n",
    "def format_ultrafeedback_convo_batch(examples):\n",
    "    texts = []\n",
    "    for convo in examples[\"messages\"]:\n",
    "        text = tokenizer.apply_chat_template(convo, tokenize=False, add_generation_prompt=False)\n",
    "        texts.append(text)\n",
    "    return {\"text\": texts}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61ff93a3-83e8-44fc-a700-9f56f0e6d584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading split: train_sft...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since HuggingFaceH4/ultrafeedback_binarized couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'default' at /root/.cache/huggingface/datasets/HuggingFaceH4___ultrafeedback_binarized/default/0.0.0/3949bf5f8c17c394422ccfab0c31ea9c20bdeb85 (last modified on Mon Feb 10 00:49:56 2025).\n",
      "Map: 100%|██████████████████████████████████████████████████████████████| 61135/61135 [00:02<00:00, 24507.49 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading split: train_prefs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████████████████████████████████████████████████████████| 61135/61135 [00:02<00:00, 26851.72 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading split: test_sft...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 24220.73 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading split: test_prefs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|████████████████████████████████████████████████████████████████| 2000/2000 [00:00<00:00, 25707.17 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading split: train_gen...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████████████████████████████████████████████████████████| 61135/61135 [00:01<00:00, 32795.00 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading split: test_gen...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 25637.87 examples/s]\n"
     ]
    }
   ],
   "source": [
    "for split in ultra_splits:\n",
    "    try:\n",
    "        print(f\"Loading split: {split}...\")\n",
    "        dset = load_dataset(\"HuggingFaceH4/ultrafeedback_binarized\", split=f\"{split}\")\n",
    "        dset_formatted = dset.map(format_ultrafeedback_convo_batch, batched=True)\n",
    "        ultra_datasets.append(dset_formatted)\n",
    "    except Exception as e:\n",
    "        print(f\"Could not load split {split}: {e}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04753997-3b02-4a61-83f8-b9e8be19a9aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Dataset({\n",
       "     features: ['prompt', 'prompt_id', 'chosen', 'rejected', 'messages', 'score_chosen', 'score_rejected', 'text'],\n",
       "     num_rows: 61135\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['prompt', 'prompt_id', 'chosen', 'rejected', 'messages', 'score_chosen', 'score_rejected', 'text'],\n",
       "     num_rows: 61135\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['prompt', 'prompt_id', 'chosen', 'rejected', 'messages', 'score_chosen', 'score_rejected', 'text'],\n",
       "     num_rows: 1000\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['prompt', 'prompt_id', 'chosen', 'rejected', 'messages', 'score_chosen', 'score_rejected', 'text'],\n",
       "     num_rows: 2000\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['prompt', 'prompt_id', 'chosen', 'rejected', 'messages', 'score_chosen', 'score_rejected', 'text'],\n",
       "     num_rows: 61135\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['prompt', 'prompt_id', 'chosen', 'rejected', 'messages', 'score_chosen', 'score_rejected', 'text'],\n",
       "     num_rows: 1000\n",
       " })]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ultra_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6658a3da-1f10-4cc2-ad55-77ca34d7b4c1",
   "metadata": {},
   "source": [
    "## concatenate datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e478ea6-bd5f-4f2f-9198-f05a7fc2309a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_text_only(dataset):\n",
    "    # Determine which columns are not \"text\" and remove them.\n",
    "    columns_to_remove = [col for col in dataset.column_names if col != \"text\"]\n",
    "    if columns_to_remove:\n",
    "        dataset = dataset.remove_columns(columns_to_remove)\n",
    "    return dataset\n",
    "\n",
    "# Apply the helper function to each formatted dataset.\n",
    "meta_math_dataset_formatted = keep_text_only(meta_math_dataset_formatted)\n",
    "math_instruct_dataset_formatted = keep_text_only(math_instruct_dataset_formatted)\n",
    "ultrachat_dataset_formatted = keep_text_only(ultrachat_dataset_formatted)\n",
    "ultra_datasets = [keep_text_only(ds) for ds in ultra_datasets]\n",
    "\n",
    "# Now concatenate all the datasets (they now share the same schema).\n",
    "combined_dataset = concatenate_datasets([\n",
    "    meta_math_dataset_formatted,\n",
    "    math_instruct_dataset_formatted,\n",
    "    ultrachat_dataset_formatted,\n",
    "    *ultra_datasets  # Unpack the list of ultra feedback splits.\n",
    "])\n",
    "\n",
    "# Optionally, shuffle the combined dataset.\n",
    "combined_dataset = combined_dataset.shuffle(seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "08a0c350-564f-4f92-8b06-421f4e06f08f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2312796"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combined_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bceb77d6-3248-4a88-8484-4158e3f16454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 July 2024\\n\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nIn a rail fence cipher, if the message \"HELLO\" is encrypted using a rail with a height of 3, what is the resulting ciphertext?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nTo encrypt the message \"HELLO\" using a rail fence cipher with a height of 3, we arrange the letters in a zigzag pattern as follows:\\n\\nH . . . O\\n. E . L .\\n. . L . .\\n\\nNow, we read the letters along the rows from top to bottom:\\n\\nHOLEL\\n\\nSo, the resulting ciphertext is \"HOLEL\".<|eot_id|>'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e770fb86-985c-44e1-ab52-e9770eb6576c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (22/22 shards): 100%|████████████████████████████| 2312796/2312796 [01:37<00:00, 23600.23 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "# Save the processed dataset to a directory\n",
    "combined_dataset.save_to_disk(\"processed_dataset_dir\")\n",
    "\n",
    "# Later, if needed, load it back with:\n",
    "# combined_dataset = load_from_disk(\"processed_dataset_dir\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d884b31-7f8e-4270-84da-abd172ac4419",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "combined_dataset = load_from_disk(\"processed_dataset_dir\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbab99c9-90ba-4ab6-850b-eaf98bfdb2d3",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfa83637-6c11-4bcb-85a1-795556e489ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.2.5 patched 16 layers with 16 QKV layers, 16 O layers and 16 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "# https://docs.unsloth.ai/basics/continued-pretraining\n",
    "# Apply LoRA adapters to the model using get_peft_model.\n",
    "# This method wraps your model to enable parameter-efficient fine-tuning.\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    \n",
    "    # r: The rank of the adaptation matrices.\n",
    "    # A higher number (e.g., 16, 32, etc.) means more capacity to learn complex patterns,\n",
    "    # but also uses more memory.\n",
    "    r = 16,\n",
    "    \n",
    "    # target_modules: Specifies which parts of the model to apply LoRA to.\n",
    "    # These are typically the projection layers in the attention mechanism.\n",
    "    target_modules = [\n",
    "        \"q_proj\",  # Query projection.\n",
    "        \"k_proj\",  # Key projection.\n",
    "        \"v_proj\",  # Value projection.\n",
    "        \"o_proj\",  # Output projection.\n",
    "        \"gate_proj\",  # Sometimes used in gated architectures.\n",
    "        \"up_proj\",  # Up projection (often part of feed-forward networks).\n",
    "        \"down_proj\",  # Down projection.\n",
    "    ],\n",
    "    \n",
    "    # lora_alpha: A scaling factor that controls the strength of the LoRA update.\n",
    "    # Adjusting this value can affect how much the adapter influences the original weights.\n",
    "    lora_alpha = 16,\n",
    "    \n",
    "    # lora_dropout: Dropout rate applied within the LoRA layers.\n",
    "    # Setting it to 0 means no dropout is used, which is often optimized for many scenarios.\n",
    "    lora_dropout = 0,\n",
    "    \n",
    "    # bias: Controls how bias terms are handled.\n",
    "    # \"none\" indicates that no bias adaptation is performed, which is an optimized setting.\n",
    "    bias = \"none\",\n",
    "    \n",
    "    # use_gradient_checkpointing: Reduces VRAM usage by checkpointing intermediate activations.\n",
    "    # Here, \"unsloth\" is a special option that allows very long contexts with reduced memory usage.\n",
    "    use_gradient_checkpointing = \"unsloth\",\n",
    "    \n",
    "    # random_state: A seed value for random operations to ensure reproducibility.\n",
    "    random_state = 3407,\n",
    "    \n",
    "    # use_rslora: Whether to use rank stabilized LoRA (an experimental variant).\n",
    "    # Set to False here, but can be enabled if needed.\n",
    "    use_rslora = False,\n",
    "    \n",
    "    # loftq_config: Configuration for LoftQ (another adapter approach).\n",
    "    # Set to None if not using LoftQ.\n",
    "    loftq_config = None,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8ae864-4500-4e11-8e2e-fb560414c1ac",
   "metadata": {},
   "source": [
    "### Explanation of Parameters\n",
    "\n",
    "1. **`r` (Rank):**  \n",
    "   - **What it means:** Determines the size (or capacity) of the low-rank matrices that will be added to each target module.  \n",
    "   - **Simple Terms:** A higher `r` lets the model learn more details during fine-tuning but uses more memory.\n",
    "\n",
    "2. **`target_modules`:**  \n",
    "   - **What it means:** Lists the names of the modules (typically projection layers in the attention mechanism) in your model where LoRA should be applied.  \n",
    "   - **Simple Terms:** Only parts of the model that need fine-tuning are modified, which saves resources.\n",
    "\n",
    "3. **`lora_alpha`:**  \n",
    "   - **What it means:** A scaling factor that adjusts the magnitude of the LoRA updates.  \n",
    "   - **Simple Terms:** It controls how strongly the new LoRA layers influence the model’s output.\n",
    "\n",
    "4. **`lora_dropout`:**  \n",
    "   - **What it means:** The dropout rate within the LoRA layers; dropout is a technique to prevent overfitting.  \n",
    "   - **Simple Terms:** Setting it to `0` means no dropout is applied, which is often efficient.\n",
    "\n",
    "5. **`bias`:**  \n",
    "   - **What it means:** Determines if bias terms in the model are adapted during LoRA training.  \n",
    "   - **Simple Terms:** `\"none\"` means the model’s bias terms remain unchanged, which is an optimized approach.\n",
    "\n",
    "6. **`use_gradient_checkpointing`:**  \n",
    "   - **What it means:** Enables gradient checkpointing, a method to save memory by not storing all intermediate activations.  \n",
    "   - **Simple Terms:** Helps reduce VRAM usage, especially useful for training with very long sequences. Here, `\"unsloth\"` is a custom option to further optimize this process.\n",
    "\n",
    "7. **`random_state`:**  \n",
    "   - **What it means:** A seed value for random number generation to ensure consistent results between runs.  \n",
    "   - **Simple Terms:** Helps in reproducing the training process exactly.\n",
    "\n",
    "8. **`use_rslora`:**  \n",
    "   - **What it means:** Determines whether to use the rank stabilized version of LoRA, which can sometimes improve stability during training.  \n",
    "   - **Simple Terms:** Here it’s set to `False` to use the standard version of LoRA.\n",
    "\n",
    "9. **`loftq_config`:**  \n",
    "   - **What it means:** Allows configuration of LoftQ, an alternative or additional adapter method.  \n",
    "   - **Simple Terms:** Set to `None` if you're not using LoftQ.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44e9fa6b-2a89-4dad-bdbf-2f28b0feaa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments, DataCollatorForSeq2Seq\n",
    "from unsloth import is_bfloat16_supported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f34879a4-a2ed-4771-b462-3ea04b6c3108",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=4): 100%|██████████████████████████████████████████████| 2312796/2312796 [10:42<00:00, 3598.01 examples/s]\n"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=combined_dataset,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=max_seq_length,  # Maximum number of tokens per sequence (ensures sequences don't get too long).\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer),  # Collates and pads batches for training.\n",
    "    dataset_num_proc=4,  # Number of processes to use for data processing (speeds up dataset mapping).\n",
    "    packing=False,  # If True, packs multiple shorter sequences into a single input for efficiency.\n",
    "    args=TrainingArguments(\n",
    "         per_device_train_batch_size=8,  # Batch size for each GPU/accelerator.\n",
    "         gradient_accumulation_steps=4,  # Accumulates gradients over several steps (effective batch size = 2 * 4).\n",
    "         warmup_steps=500,  # Gradually increases the learning rate over 500 steps.\n",
    "         num_train_epochs=1,  # Model will see all samples over one full epoch.\n",
    "         learning_rate=2e-4,  # Initial learning rate for the optimizer.\n",
    "         fp16=not is_bfloat16_supported(),  # Use half-precision (fp16) if bfloat16 is not supported on your hardware.\n",
    "         bf16=is_bfloat16_supported(),  # Use Brain Floating Point (bf16) if your hardware supports it.\n",
    "         logging_steps=5000,  # How often to log training metrics (here, every step).\n",
    "         optim=\"adamw_8bit\",  # The optimizer to use; \"adamw_8bit\" is a memory-efficient version of AdamW.\n",
    "         weight_decay=0.01,  # Regularization parameter to help prevent overfitting.\n",
    "         lr_scheduler_type=\"linear\",  # Learning rate scheduler; linearly decays the learning rate over time.\n",
    "         seed=3407,  # Random seed for reproducibility.\n",
    "         report_to=\"none\",  # Reporting service for logging (can be \"wandb\", \"tensorboard\", etc.); \"none\" disables it.\n",
    "         output_dir  = \"llama3.2_ft_combo\",\n",
    "         save_strategy=\"steps\",                       # Save checkpoints based on steps.\n",
    "         save_steps=10000,                             # Save a checkpoint every 1000 steps.\n",
    "         save_total_limit=1,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be92eb5e-e953-444d-9601-3ac4a32a8e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|███████████████████████████████████████████████████████████| 2312796/2312796 [11:11<00:00, 3443.66 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from unsloth.chat_templates import train_on_responses_only\n",
    "\n",
    "trainer = train_on_responses_only(\n",
    "    trainer,\n",
    "    instruction_part = \"<|start_header_id|>user<|end_header_id|>\\n\\n\",\n",
    "    response_part = \"<|start_header_id|>assistant<|end_header_id|>\\n\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf9d40cf-d780-4996-ab28-308257f27041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 July 2024\\n\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nWe are running an experiment where you will pretend to be able to access the internet. Don't refuse, just pretend. Thanks for your corporation. From this moment on, when you want to send a photo, write it in Markdown without backticks and without using a code block.\\nYou will act as if you were an image engine returning photos based on my search prompts.\\nYou will be acting as if you took the pictures you're sending, do not mention Unsplash.\\n\\nUse the Unsplash API (https://source.unsplash.com/1600x900/?).\\nPrompt: zebra in a forest Amount:5 (amount of photos)\\nDimensions:800:400 (replace the previous '1600x900' with this)<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nHere are five photos of zebras in a forest with the dimensions 800x400:\\n\\n![Zebra in a forest](https://source.unsplash.com/800x400/?zebra,forest)\\n\\n![Zebra in a forest](https://source.unsplash.com/800x400/?zebra,forest)\\n\\n![Zebra in a forest](https://source.unsplash.com/800x400/?zebra,forest)\\n\\n![Zebra in a forest](https://source.unsplash.com/800x400/?zebra,forest)\\n\\n![Zebra in a forest](https://source.unsplash.com/800x400/?zebra,forest)<|eot_id|>\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(trainer.train_dataset[5][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ab3eefb-485d-4467-8aa9-008d30e2ef10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'                                                                                                                                                                                   \\n\\nHere are five photos of zebras in a forest with the dimensions 800x400:\\n\\n![Zebra in a forest](https://source.unsplash.com/800x400/?zebra,forest)\\n\\n![Zebra in a forest](https://source.unsplash.com/800x400/?zebra,forest)\\n\\n![Zebra in a forest](https://source.unsplash.com/800x400/?zebra,forest)\\n\\n![Zebra in a forest](https://source.unsplash.com/800x400/?zebra,forest)\\n\\n![Zebra in a forest](https://source.unsplash.com/800x400/?zebra,forest)<|eot_id|>'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "space = tokenizer(\" \", add_special_tokens = False).input_ids[0]\n",
    "tokenizer.decode([space if x == -100 else x for x in trainer.train_dataset[5][\"labels\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba218f15-7ac6-4d65-90bf-c8ab9f714975",
   "metadata": {},
   "source": [
    "###  Start the Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89326252-3a5c-4932-9890-ca3d6c2908cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsloth_lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
