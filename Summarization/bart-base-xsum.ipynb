{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'xsum'...\n"
     ]
    }
   ],
   "source": [
    "!git clone https://huggingface.co/datasets/EdinburghNLP/xsum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the XSum Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\priks\\anaconda3\\envs\\t\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "raw_datasets = load_dataset(\"xsum/xsum.py\", trust_remote_code=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['document', 'summary', 'id'],\n",
       "        num_rows: 204045\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['document', 'summary', 'id'],\n",
       "        num_rows: 11332\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['document', 'summary', 'id'],\n",
       "        num_rows: 11334\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Switch to a smaller model (bart-base)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "'>> Document: \n",
      "\n",
      "In Wales, councils are responsible for funding and overseeing schools.\n",
      "But in England, Mr Osborne's plan will mean local authorities will cease to have a role in providing education.\n",
      "Academies are directly funded by central government and head teachers have more freedom over admissions and to change the way the school works.\n",
      "It is a significant development in the continued divergence of schools systems on either side of Offa's Dyke.\n",
      "And although the Welsh Government will get extra cash to match the money for English schools to extend the school day, it can spend it on any devolved policy area.\n",
      "Ministers have no plans to follow suit.\n",
      "At the moment, governing bodies are responsible for setting school hours and they need ministerial permission to make significant changes.\n",
      "There are already more than 2,000 secondary academies in England and its extension to all state schools is unlikely to shake the Welsh Government's attachment to what they call a \"community, comprehensive model\" for schools.\n",
      "It rejects claims that freedom given to academies can help drive up standards, and it points to academy-free Scotland as the best performing school system in the UK.\n",
      "Education Minister Huw Lewis said there was \"very little evidence to suggest\" academies have a positive impact in driving up standards and Wales would not be following the model.\n",
      "\"The Tories have wasted hundreds of millions of pounds on academies and free schools and as the Chancellor finalises his budget plans to slash vital services even further, he is committing them to wasting even more on a failing endeavour.\n",
      "\"We have no plans to introduce the chaos and waste of academies and free schools here in Wales.\"\n",
      "None of the main parties in May's Assembly election - including the Welsh Conservatives - have said they want to introduce academies in Wales.\n",
      "Owen Hathway, NUT Cymru's policy officer, called the academy plans for England \"scandalous.\".\n",
      "\"There is no evidence that academies work, no evidence that they raise standards, no evidence that they offer better quality education and no evidence that they are what parents and communities want,\" he said.\n",
      "\"Certainly a commitment to comprehensive education is something we would want, and indeed expect, all parties to hold firm to in their manifestos for the forthcoming Welsh election.\"\n",
      "But the Welsh and English schools systems are still linked by a joint arrangement for teachers' pay and conditions.\n",
      "Academies are not tied to these pay scales so in effect Wednesday's announcement will take all English schools out of the system and raise questions about the viability of an England and Wales pay and conditions structure.\n",
      "There is already growing momentum for the devolution of teachers' pay and conditions.\n",
      "Originally sceptical, the Welsh Labour Government is now broadly in favour.\n",
      "Some teaching unions remain opposed because of concern that Welsh teachers would end up being paid less than those in England.\n",
      "Mr Hathway said teachers were concerned it could lead to regional pay.\n",
      "\"At the same time we do of course recognise that the issue of pay is already becoming a grey area due to the negative changes we see taking place in England,\" he said.\n",
      "But an even bigger difference between the schools landscape on either side of the border, appears to make separate arrangements for pay increasingly likely in future.'\n",
      "----------------------------------------------------------------------------------------------------\n",
      "'>> Summary: \n",
      "\n",
      "As Chancellor George Osborne announced all English state schools will become academies, the Welsh Government continues to reject the model here.'\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "'>> Document: \n",
      "\n",
      "Up to 100,000 youngsters will be eligible for half-price day tickets using The Young Persons 16-18 card from September.\n",
      "It was agreed by the area's mayor Andy Burnham and Transport for Greater Manchester, and a similar scheme is being considered for the Metrolink.\n",
      "Hajrah Ahmed, 17, said half-price bus tickets \"will be such a big help\".\n",
      "The Manchester College business student who travels to Openshaw from Cheetham Hill every day said her journeys are costing Â£100 per month.\n",
      "\"[It] is obviously an awful lot of money for someone like me, who doesn't have a part-time job.\n",
      "\"I can look ahead to the next year or so without the worry of how much money I am spending on my journey,\" she said.\n",
      "The deal was proposed by Mr Burnham in his manifesto for mayor in April.\n",
      "\"I promised to help our young people get on in life, and this is the first step in delivering on that,\" Mr Burnham said.\n",
      "Greater Manchester Travelcards Ltd, which represents all bus companies in the area, will extend its multi-operator 50% discounted 16-and-under ticket.\n",
      "A junior day ticket to cover 16 to 18 year olds will also be introduced.\n",
      "Eligibility to use the ticket will run up to 31 August after the user's 18th birthday.'\n",
      "----------------------------------------------------------------------------------------------------\n",
      "'>> Summary: \n",
      "\n",
      "Discounted bus tickets for 16 to 18 year olds will be rolled out in Greater Manchester, it has been announced.'\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "'>> Document: \n",
      "\n",
      "Middlesbrough and Brighton face each other on Saturday, with the winner guaranteed automatic promotion to the Premier League.\n",
      "The two sides are level on points and separated only by goal difference. A draw will see Boro promoted and send the Seagulls into the play-offs.\n",
      "BBC Sport looks back at five dramatic deciders from years past. Will the Championship season's climax rival any of these classics?\n",
      "Liverpool 0-2 Arsenal, 1989\n",
      "Liverpool led the First Division table by three points before their final league game of the season against closest rivals Arsenal at Anfield.\n",
      "If they avoided a two-goal home defeat, the Reds would become the first English team to win the double for a second time.\n",
      "Arsenal, leading 1-0 through Alan Smith, entered stoppage time needing to score once more to be champions.\n",
      "Cue a moment of iconic commentary from ITV's Brian Moore: \"Smith for Thomas, charging through the midfield...\n",
      "\"Thomas, it's up for grabs now... Thomas! Right at the end! An unbelievable climax to the league season!\"\n",
      "Manchester City 0-1 Luton, 1983\n",
      "Long before Paul Dickov's play-off final goal at Wembley in 1999 or Sergio Aguero's Premier League title-winner in 2012, Manchester City found themselves on the wrong end of some late drama.\n",
      "City only needed a draw with Luton at Maine Road to ensure top-flight survival, while the Hatters needed to win to stay up and send City down.\n",
      "As full-time approached, Raddy Antic fired in the from the edge of the penalty area to put the visitors ahead.\n",
      "\"Has Luton's life in the harsh world of the English First Division been saved by a Yugoslav?\" asked BBC commentator John Motson.\n",
      "Yes it had, and who can forget the sight of Luton manager David Pleat racing onto the pitch to celebrate with his players?\n",
      "Brentford 0-1 Doncaster, 2013\n",
      "How joy can turn to despair, and vice versa, in 18 seconds. Brentford fans and Marcello Trotta - look away now.\n",
      "Doncaster began the final day of the League One season needing a draw at Griffin Park to be promoted. A Brentford win would have taken the Bees up instead.\n",
      "With the score 0-0 in the 94th minute, referee Michael Oliver awarded the home side a penalty. Trotta stepped up and thumped it against the crossbar.\n",
      "Rovers immediately broke forward and James Coppinger netted the winner for the visitors at the other end.\n",
      "That goal and results elsewhere meant Doncaster were champions. Brentford finished third and lost to Yeovil in the play-off final.\n",
      "Chelsea 2-1 Liverpool, 2003\n",
      "This is the tale of how Jesper Gronkjaer helped Chelsea win four Premier League titles, four FA Cups, the Europa League and the Champions League.\n",
      "That may sound a little far-fetched, but Chelsea could have been a far different club had the Denmark international winger not scored the winner in the Blues' final game of the 2002-03 Premier League campaign against Liverpool.\n",
      "Victory guaranteed Claudio Ranieri's side a place in the following season's Champions League. A few weeks later, Russian billionaire Roman Abramovich completed his takeover of Chelsea, who were reported to be Â£80m in debt at the time.\n",
      "Abramovich's investment since then? It is estimated to be more than Â£1bn.\n",
      "Hereford 1-1 Brighton, 1997\n",
      "Forget fighting for a Premier League place - as recently as 1997, Brighton were fighting to stay in the Football League.\n",
      "Defeat at bottom club Hereford on the final day of the season would have left Brighton contemplating life in the Conference. \"There's an awful lot at stake,\" said boss Steve Gritt.\n",
      "Kerry Mayo's own goal put Hereford in front but Robbie Reinelt netted the equaliser that Brighton required to preserve their Football League status.\n",
      "It was an emotional moment for their supporters, who had seen the Seagulls win their final game at the Goldstone Ground - their home for nearly a century - a week earlier.\n",
      "Gritt, who had taken charge five months earlier with Brighton 11 points adrift at the bottom of the fourth tier, admitted afterwards: \"It's not something I really want to go through again.\"'\n",
      "----------------------------------------------------------------------------------------------------\n",
      "'>> Summary: \n",
      "\n",
      "\"The winner takes it all, the loser has to fall...\"'\n"
     ]
    }
   ],
   "source": [
    "def show_samples(dataset, num_samples=3, seed=42):\n",
    "    sample = raw_datasets[\"train\"].shuffle(seed=seed).select(range(num_samples))\n",
    "    for example in sample:\n",
    "        print(\"-\" * 100)\n",
    "        print(f\"\\n'>> Document: \\n\\n{example['document']}'\")\n",
    "        print(\"-\" * 100)\n",
    "        print(f\"'>> Summary: \\n\\n{example['summary']}'\")\n",
    "\n",
    "show_samples(raw_datasets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set - Document Token Counts - Average: 488.6465289519469, Min: 2, Max: 35314\n",
      "Train Set - Summary Token Counts - Average: 28.147403758974736, Min: 3, Max: 118\n",
      "Train Set - Document Word Counts - Average: 373.8646328015879, Min: 0, Max: 29189\n",
      "Train Set - Summary Word Counts - Average: 21.09764512730035, Min: 1, Max: 70\n",
      "--------------------------------------------------\n",
      "Validation Set - Document Token Counts - Average: 481.9947052594423, Min: 2, Max: 6563\n",
      "Validation Set - Summary Token Counts - Average: 28.146664313448643, Min: 5, Max: 102\n",
      "Validation Set - Document Word Counts - Average: 369.1336039534063, Min: 0, Max: 3937\n",
      "Validation Set - Summary Word Counts - Average: 21.126720790681258, Min: 1, Max: 86\n",
      "--------------------------------------------------\n",
      "Test Set - Document Token Counts - Average: 491.47714840303513, Min: 2, Max: 15278\n",
      "Test Set - Summary Token Counts - Average: 28.141697547203105, Min: 5, Max: 103\n",
      "Test Set - Document Word Counts - Average: 376.1446973707429, Min: 0, Max: 10315\n",
      "Test Set - Summary Word Counts - Average: 21.097582495147343, Min: 2, Max: 74\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Add token count for documents\n",
    "def check_token_count(examples):\n",
    "    tokens = tokenizer(examples[\"document\"], truncation=False)\n",
    "    return {\"token_count\": [len(token_ids) for token_ids in tokens[\"input_ids\"]]}\n",
    "\n",
    "raw_datasets = raw_datasets.map(check_token_count, batched=True)\n",
    "\n",
    "# Add token count for summaries\n",
    "def check_summary_token_count(examples):\n",
    "    tokens = tokenizer(examples[\"summary\"], truncation=False)\n",
    "    return {\"summary_token_count\": [len(token_ids) for token_ids in tokens[\"input_ids\"]]}\n",
    "\n",
    "raw_datasets = raw_datasets.map(check_summary_token_count, batched=True)\n",
    "\n",
    "# Add word count for documents\n",
    "def check_word_count(examples):\n",
    "    return {\"word_count\": [len(doc.split()) for doc in examples[\"document\"]]}\n",
    "\n",
    "raw_datasets = raw_datasets.map(check_word_count, batched=True)\n",
    "\n",
    "# Add word count for summaries\n",
    "def check_summary_word_count(examples):\n",
    "    return {\"summary_word_count\": [len(summ.split()) for summ in examples[\"summary\"]]}\n",
    "\n",
    "raw_datasets = raw_datasets.map(check_summary_word_count, batched=True)\n",
    "\n",
    "# Function to calculate statistics\n",
    "def calculate_statistics(counts):\n",
    "    counts_np = np.array(counts)\n",
    "    avg_count = np.mean(counts_np)\n",
    "    min_count = np.min(counts_np)\n",
    "    max_count = np.max(counts_np)\n",
    "    return avg_count, min_count, max_count\n",
    "\n",
    "# Calculate statistics for each split\n",
    "for split in raw_datasets:\n",
    "    doc_token_counts = raw_datasets[split][\"token_count\"]\n",
    "    summary_token_counts = raw_datasets[split][\"summary_token_count\"]\n",
    "    doc_word_counts = raw_datasets[split][\"word_count\"]\n",
    "    summary_word_counts = raw_datasets[split][\"summary_word_count\"]\n",
    "    \n",
    "    doc_token_avg, doc_token_min, doc_token_max = calculate_statistics(doc_token_counts)\n",
    "    summary_token_avg, summary_token_min, summary_token_max = calculate_statistics(summary_token_counts)\n",
    "    doc_word_avg, doc_word_min, doc_word_max = calculate_statistics(doc_word_counts)\n",
    "    summary_word_avg, summary_word_min, summary_word_max = calculate_statistics(summary_word_counts)\n",
    "    \n",
    "    print(f\"{split.capitalize()} Set - Document Token Counts - Average: {doc_token_avg}, Min: {doc_token_min}, Max: {doc_token_max}\")\n",
    "    print(f\"{split.capitalize()} Set - Summary Token Counts - Average: {summary_token_avg}, Min: {summary_token_min}, Max: {summary_token_max}\")\n",
    "    print(f\"{split.capitalize()} Set - Document Word Counts - Average: {doc_word_avg}, Min: {doc_word_min}, Max: {doc_word_max}\")\n",
    "    print(f\"{split.capitalize()} Set - Summary Word Counts - Average: {summary_word_avg}, Min: {summary_word_min}, Max: {summary_word_max}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total examples: 204045\n",
      "Remaining after filtering: 203966\n",
      "Removed examples: 79 (0.04%)\n",
      "Total examples: 11332\n",
      "Remaining after filtering: 11326\n",
      "Removed examples: 6 (0.05%)\n",
      "Total examples: 11334\n",
      "Remaining after filtering: 11331\n",
      "Removed examples: 3 (0.03%)\n"
     ]
    }
   ],
   "source": [
    "from datasets import DatasetDict\n",
    "\n",
    "# Filter dataset based on token and word counts\n",
    "def filter_dataset(dataset, min_doc_tokens=10, min_summary_tokens=5):\n",
    "    def is_valid_example(example):\n",
    "        return (example['token_count'] >= min_doc_tokens and\n",
    "                example['summary_token_count'] >= min_summary_tokens and\n",
    "                example['word_count'] > 0)\n",
    "    \n",
    "    filtered_dataset = dataset.filter(is_valid_example)\n",
    "    \n",
    "    print(f\"Total examples: {len(dataset)}\")\n",
    "    print(f\"Remaining after filtering: {len(filtered_dataset)}\")\n",
    "    print(f\"Removed examples: {len(dataset) - len(filtered_dataset)} ({(len(dataset) - len(filtered_dataset)) / len(dataset) * 100:.2f}%)\")\n",
    "    \n",
    "    return filtered_dataset\n",
    "\n",
    "filtered_datasets = DatasetDict({\n",
    "    split: filter_dataset(raw_datasets[split])\n",
    "    for split in raw_datasets.keys()\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['document', 'summary', 'id', 'token_count', 'summary_token_count', 'word_count', 'summary_word_count'],\n",
       "        num_rows: 203966\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['document', 'summary', 'id', 'token_count', 'summary_token_count', 'word_count', 'summary_word_count'],\n",
       "        num_rows: 11326\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['document', 'summary', 'id', 'token_count', 'summary_token_count', 'word_count', 'summary_word_count'],\n",
       "        num_rows: 11331\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset for training\n",
    "max_input_length = 1024\n",
    "max_target_length = 512\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    model_inputs = tokenizer(\n",
    "        examples[\"document\"],\n",
    "        max_length=max_input_length,\n",
    "        truncation=True,\n",
    "    )\n",
    "    \n",
    "    labels = tokenizer(\n",
    "        examples[\"summary\"],\n",
    "        max_length=max_target_length,\n",
    "        truncation=True,\n",
    "    )\n",
    "    \n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_datasets = filtered_datasets.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/bart-base\")\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\priks\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import evaluate\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "rouge_score = evaluate.load(\"rouge\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    # Decode generated summaries into text\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    # Replace -100 in the labels as we can't decode them\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    # Decode reference summaries into text\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    # ROUGE expects a newline after each sentence\n",
    "    decoded_preds = [\"\\n\".join(sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "    # Compute ROUGE scores\n",
    "    result = rouge_score.compute(\n",
    "        predictions=decoded_preds, references=decoded_labels, use_stemmer=True\n",
    "    )\n",
    "    # Extract the median scores\n",
    "    result = {key: value * 100 for key, value in result.items()}\n",
    "    return {k: round(v, 4) for k, v in result.items()}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\priks\\anaconda3\\envs\\t\\lib\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ð¤ Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./bart-base-xsum-checkpoints\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    gradient_accumulation_steps=1,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=5,\n",
    "    warmup_steps=1000,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    predict_with_generate=True,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"rougeL\",\n",
    "    greater_is_better=True,\n",
    "    fp16=True,\n",
    "    label_smoothing_factor=0.1,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\priks\\AppData\\Local\\Temp\\ipykernel_4252\\1388523178.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n",
      "c:\\Users\\priks\\anaconda3\\envs\\t\\lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:496: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63740' max='63740' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63740/63740 9:43:59, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.340200</td>\n",
       "      <td>3.164266</td>\n",
       "      <td>37.495700</td>\n",
       "      <td>16.015800</td>\n",
       "      <td>30.764100</td>\n",
       "      <td>30.765900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.176300</td>\n",
       "      <td>3.095118</td>\n",
       "      <td>38.216500</td>\n",
       "      <td>16.882100</td>\n",
       "      <td>31.515700</td>\n",
       "      <td>31.512700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.044800</td>\n",
       "      <td>3.061704</td>\n",
       "      <td>38.840400</td>\n",
       "      <td>17.552200</td>\n",
       "      <td>32.200000</td>\n",
       "      <td>32.199200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.983100</td>\n",
       "      <td>3.051939</td>\n",
       "      <td>39.207500</td>\n",
       "      <td>17.844900</td>\n",
       "      <td>32.408700</td>\n",
       "      <td>32.408100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.922600</td>\n",
       "      <td>3.050806</td>\n",
       "      <td>39.207900</td>\n",
       "      <td>17.868600</td>\n",
       "      <td>32.477700</td>\n",
       "      <td>32.473400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\priks\\anaconda3\\envs\\t\\lib\\site-packages\\transformers\\modeling_utils.py:2758: UserWarning: Moving the following attributes in the config to the generation config: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n",
      "There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight', 'lm_head.weight'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=63740, training_loss=3.126221167543745, metrics={'train_runtime': 35039.9492, 'train_samples_per_second': 29.105, 'train_steps_per_second': 1.819, 'total_flos': 6.008027139794534e+17, 'train_loss': 3.126221167543745, 'epoch': 5.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Save model and tokenizer\n",
    "model_output_dir = \"bart-base-xsum\"\n",
    "trainer.save_model(model_output_dir)\n",
    "tokenizer.save_pretrained(model_output_dir)\n",
    "\n",
    "# Save training logs\n",
    "metrics_output_file = model_output_dir + \"/log_history.json\"\n",
    "with open(metrics_output_file, \"w\") as f:\n",
    "    json.dump(trainer.state.log_history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='709' max='354' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [354/354 1:03:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Metrics: {'eval_loss': 3.0508058071136475, 'eval_rouge1': 39.2079, 'eval_rouge2': 17.8686, 'eval_rougeL': 32.4777, 'eval_rougeLsum': 32.4734, 'eval_runtime': 3226.566, 'eval_samples_per_second': 3.51, 'eval_steps_per_second': 0.11, 'epoch': 5.0}\n",
      "Test Set Metrics: {'eval_loss': 3.0606689453125, 'eval_rouge1': 39.2149, 'eval_rouge2': 17.7573, 'eval_rougeL': 32.419, 'eval_rougeLsum': 32.402, 'eval_runtime': 585.0005, 'eval_samples_per_second': 19.369, 'eval_steps_per_second': 0.607, 'epoch': 5.0}\n"
     ]
    }
   ],
   "source": [
    "metrics = trainer.evaluate()\n",
    "print(\"Validation Set Metrics:\", metrics)\n",
    "\n",
    "test_metrics = trainer.evaluate(eval_dataset=tokenized_datasets[\"test\"])\n",
    "print(\"Test Set Metrics:\", test_metrics)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\priks\\anaconda3\\envs\\t\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Device set to use cuda:0\n",
      "Your max_length is set to 128, but your input_length is only 80. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=40)\n",
      "c:\\Users\\priks\\anaconda3\\envs\\t\\lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:496: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Summary: Scientists at the University of California, Berkeley, have developed a new type of solar panel.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the summarization pipeline using the fine-tuned model\n",
    "summarizer = pipeline(\"summarization\", model=\"bart-base-xsum\")\n",
    "\n",
    "# Input text for summarization\n",
    "text = (\n",
    "    \"In a significant breakthrough in renewable energy, scientists have developed \"\n",
    "    \"a novel solar panel technology that promises to dramatically reduce costs and \"\n",
    "    \"increase efficiency. The new panels are lighter, more durable, and easier to install \"\n",
    "    \"than conventional models, marking a major advancement in sustainable energy solutions. \"\n",
    "    \"Experts believe this innovation could lead to wider adoption of solar power across residential \"\n",
    "    \"and commercial sectors, ultimately reducing global reliance on fossil fuels.\"\n",
    ")\n",
    "\n",
    "# Generate summary\n",
    "summary = summarizer(text)[0][\"summary_text\"]\n",
    "print(\"Generated Summary:\", summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "t",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
